{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Baitapthuhanh2\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\" , \"D:/New-folder-1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_schema_struct = StructType([\n",
    "    StructField(\"LYLTY_CARD_NBR\", LongType()),\n",
    "    StructField(\"DATE\", DateType()),\n",
    "    StructField(\"STORE_NBR\", LongType()),\n",
    "    StructField(\"TXN_ID\", LongType()),\n",
    "    StructField(\"PROD_NBR\", LongType()),\n",
    "    StructField(\"PROD_NAME\", StringType()),\n",
    "    StructField(\"PROD_QTY\", LongType()),\n",
    "    StructField(\"TOT_SALES\", FloatType()),\n",
    "    StructField(\"PACK_SIZE\", LongType()),\n",
    "    StructField(\"BRAND\", StringType()),\n",
    "    StructField(\"LIFESTAGE\", StringType()),\n",
    "    StructField(\"PREMIUM_CUSTOMER\", StringType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(orders_schema_struct) \\\n",
    "    .load(\"D:/New-folder-1/QVI_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+---------+------+--------+--------------------+--------+---------+---------+----------+--------------------+----------------+\n",
      "|LYLTY_CARD_NBR|      DATE|STORE_NBR|TXN_ID|PROD_NBR|           PROD_NAME|PROD_QTY|TOT_SALES|PACK_SIZE|     BRAND|           LIFESTAGE|PREMIUM_CUSTOMER|\n",
      "+--------------+----------+---------+------+--------+--------------------+--------+---------+---------+----------+--------------------+----------------+\n",
      "|          1000|2018-10-17|        1|     1|       5|Natural Chip     ...|       2|      6.0|      175|   NATURAL|YOUNG SINGLES/COU...|         Premium|\n",
      "|          1002|2018-09-16|        1|     2|      58|Red Rock Deli Chi...|       1|      2.7|      150|       RRD|YOUNG SINGLES/COU...|      Mainstream|\n",
      "|          1003|2019-03-07|        1|     3|      52|Grain Waves Sour ...|       1|      3.6|      210|   GRNWVES|      YOUNG FAMILIES|          Budget|\n",
      "|          1003|2019-03-08|        1|     4|     106|Natural ChipCo   ...|       1|      3.0|      175|   NATURAL|      YOUNG FAMILIES|          Budget|\n",
      "|          1004|2018-11-02|        1|     5|      96|WW Original Stack...|       1|      1.9|      160|WOOLWORTHS|OLDER SINGLES/COU...|      Mainstream|\n",
      "|          1005|2018-12-28|        1|     6|      86|  Cheetos Puffs 165g|       1|      2.8|      165|   CHEETOS|MIDAGE SINGLES/CO...|      Mainstream|\n",
      "|          1007|2018-12-04|        1|     7|      49|Infuzions SourCre...|       1|      3.8|      110| INFUZIONS|YOUNG SINGLES/COU...|          Budget|\n",
      "|          1007|2018-12-05|        1|     8|      10|RRD SR Slow Rst  ...|       1|      2.7|      150|       RRD|YOUNG SINGLES/COU...|          Budget|\n",
      "|          1009|2018-11-20|        1|     9|      20|Doritos Cheese   ...|       1|      5.7|      330|   DORITOS|        NEW FAMILIES|         Premium|\n",
      "|          1010|2018-09-09|        1|    10|      51|Doritos Mexicana ...|       2|      8.8|      170|   DORITOS|YOUNG SINGLES/COU...|      Mainstream|\n",
      "|          1010|2018-12-14|        1|    11|      59|Old El Paso Salsa...|       1|      5.1|      300|       OLD|YOUNG SINGLES/COU...|      Mainstream|\n",
      "|          1011|2018-07-29|        1|    12|      84|GrnWves Plus Btro...|       2|      6.2|      180|   GRNWVES|OLDER SINGLES/COU...|      Mainstream|\n",
      "+--------------+----------+---------+------+--------+--------------------+--------+---------+---------+----------+--------------------+----------------+\n",
      "only showing top 12 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"orders_tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+---------+------+--------+--------------------+--------+---------+---------+----------+--------------------+----------------+\n",
      "|LYLTY_CARD_NBR|      DATE|STORE_NBR|TXN_ID|PROD_NBR|           PROD_NAME|PROD_QTY|TOT_SALES|PACK_SIZE|     BRAND|           LIFESTAGE|PREMIUM_CUSTOMER|\n",
      "+--------------+----------+---------+------+--------+--------------------+--------+---------+---------+----------+--------------------+----------------+\n",
      "|          1000|2018-10-17|        1|     1|       5|Natural Chip     ...|       2|      6.0|      175|   NATURAL|YOUNG SINGLES/COU...|         Premium|\n",
      "|          1002|2018-09-16|        1|     2|      58|Red Rock Deli Chi...|       1|      2.7|      150|       RRD|YOUNG SINGLES/COU...|      Mainstream|\n",
      "|          1003|2019-03-07|        1|     3|      52|Grain Waves Sour ...|       1|      3.6|      210|   GRNWVES|      YOUNG FAMILIES|          Budget|\n",
      "|          1003|2019-03-08|        1|     4|     106|Natural ChipCo   ...|       1|      3.0|      175|   NATURAL|      YOUNG FAMILIES|          Budget|\n",
      "|          1004|2018-11-02|        1|     5|      96|WW Original Stack...|       1|      1.9|      160|WOOLWORTHS|OLDER SINGLES/COU...|      Mainstream|\n",
      "+--------------+----------+---------+------+--------+--------------------+--------+---------+---------+----------+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from orders_tmp\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|PREMIUM_CUSTOMER| count|\n",
      "+----------------+------+\n",
      "|         Premium| 69689|\n",
      "|          Budget| 93157|\n",
      "|      Mainstream|101988|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"PREMIUM_CUSTOMER\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|PREMIUM_CUSTOMER|count(1)|\n",
      "+----------------+--------+\n",
      "|         Premium|   69689|\n",
      "|          Budget|   93157|\n",
      "|      Mainstream|  101988|\n",
      "+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select PREMIUM_CUSTOMER, count(*) from orders_tmp group by PREMIUM_CUSTOMER\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|           PROD_NAME|total_quantity|\n",
      "+--------------------+--------------+\n",
      "|Kettle Mozzarella...|          6381|\n",
      "|Kettle Tortilla C...|          6309|\n",
      "|Cobs Popd Sea Sal...|          6277|\n",
      "|Cobs Popd Swt/Chl...|          6256|\n",
      "|Tostitos Splash O...|          6234|\n",
      "|Tyrrells Crisps  ...|          6227|\n",
      "|Kettle 135g Swt P...|          6212|\n",
      "|Infuzions Thai Sw...|          6206|\n",
      "|Thins Potato Chip...|          6185|\n",
      "|Doritos Corn Chip...|          6180|\n",
      "+--------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"PROD_NAME\") \\\n",
    "  .agg(F.sum(\"PROD_QTY\").alias(\"total_quantity\")) \\\n",
    "  .sort(\"total_quantity\", ascending=False) \\\n",
    "  .show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|           PROD_NAME|total_quantity|\n",
      "+--------------------+--------------+\n",
      "|Kettle Mozzarella...|          6381|\n",
      "|Kettle Tortilla C...|          6309|\n",
      "|Cobs Popd Sea Sal...|          6277|\n",
      "|Cobs Popd Swt/Chl...|          6256|\n",
      "|Tostitos Splash O...|          6234|\n",
      "|Tyrrells Crisps  ...|          6227|\n",
      "|Kettle 135g Swt P...|          6212|\n",
      "|Infuzions Thai Sw...|          6206|\n",
      "|Thins Potato Chip...|          6185|\n",
      "|Doritos Corn Chip...|          6180|\n",
      "+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select `PROD_NAME`, SUM(PROD_QTY) as total_quantity from orders_tmp group by `PROD_NAME` order by total_quantity desc limit 10\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"PROD_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|numPROD_NAME|\n",
      "+------------+\n",
      "|         114|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct `PROD_NAME`) as numPROD_NAME from orders_tmp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|Customer Name|count|\n",
      "+-------------+-----+\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top1 = df.where(\"Category = 'Technology'\").groupBy(\"Customer Name\").count().sort(\"count\", ascending = False).limit(1)\n",
    "top1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|Customer Name|numOrders|\n",
      "+-------------+---------+\n",
      "+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select `Customer Name`, count(*) as numOrders from orders_tmp where Category = 'Technology' group by `Customer Name` order by numOrders desc limit 1\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thuchanhdataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+---------+---------+-----------+-------------+-------+-------+----+-----+-----------+------+----------+--------+------------+------------+-----+--------+--------+------+\n",
      "|Row ID|Order ID|Order Date|Ship Date|Ship Mode|Customer ID|Customer Name|Segment|Country|City|State|Postal Code|Region|Product ID|Category|Sub-Category|Product Name|Sales|Quantity|Discount|Profit|\n",
      "+------+--------+----------+---------+---------+-----------+-------------+-------+-------+----+-----+-----------+------+----------+--------+------------+------------+-----+--------+--------+------+\n",
      "|  NULL|    NULL|      NULL|     NULL|     NULL|       NULL|         NULL|   NULL|   NULL|NULL| NULL|       NULL|  NULL|      NULL|    NULL|        NULL|        NULL| NULL|    NULL|    NULL|  NULL|\n",
      "|  NULL|    NULL|      NULL|     NULL|     NULL|       NULL|         NULL|   NULL|   NULL|NULL| NULL|       NULL|  NULL|      NULL|    NULL|        NULL|        NULL| NULL|    NULL|    NULL|  NULL|\n",
      "|  NULL|    NULL|      NULL|     NULL|     NULL|       NULL|         NULL|   NULL|   NULL|NULL| NULL|       NULL|  NULL|      NULL|    NULL|        NULL|        NULL| NULL|    NULL|    NULL|  NULL|\n",
      "|  NULL|    NULL|      NULL|     NULL|     NULL|       NULL|         NULL|   NULL|   NULL|NULL| NULL|       NULL|  NULL|      NULL|    NULL|        NULL|        NULL| NULL|    NULL|    NULL|  NULL|\n",
      "|  NULL|    NULL|      NULL|     NULL|     NULL|       NULL|         NULL|   NULL|   NULL|NULL| NULL|       NULL|  NULL|      NULL|    NULL|        NULL|        NULL| NULL|    NULL|    NULL|  NULL|\n",
      "+------+--------+----------+---------+---------+-----------+-------------+-------+-------+----+-----+-----------+------+----------+--------+------------+------------+-----+--------+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.createOrReplaceTempView(\"sales_order\")\n",
    "spark.sql(\"select * from sales_order\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+--------+-------+-----+\n",
      "|Order ID|Sales|Quantity|Discount|Profit1|Total|\n",
      "+--------+-----+--------+--------+-------+-----+\n",
      "|    NULL| NULL|    NULL|    NULL|   NULL| NULL|\n",
      "|    NULL| NULL|    NULL|    NULL|   NULL| NULL|\n",
      "|    NULL| NULL|    NULL|    NULL|   NULL| NULL|\n",
      "|    NULL| NULL|    NULL|    NULL|   NULL| NULL|\n",
      "|    NULL| NULL|    NULL|    NULL|   NULL| NULL|\n",
      "|    NULL| NULL|    NULL|    NULL|   NULL| NULL|\n",
      "|    NULL| NULL|    NULL|    NULL|   NULL| NULL|\n",
      "|    NULL| NULL|    NULL|    NULL|   NULL| NULL|\n",
      "|    NULL| NULL|    NULL|    NULL|   NULL| NULL|\n",
      "|    NULL| NULL|    NULL|    NULL|   NULL| NULL|\n",
      "+--------+-----+--------+--------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    `Order ID`,\n",
    "    Sales,\n",
    "    Quantity,\n",
    "    Discount,\n",
    "    Sales * Quantity AS Profit1,\n",
    "    Sales * Quantity * (1 - COALESCE(Discount, 0)) AS Total\n",
    "FROM sales_order\n",
    "\"\"\")\n",
    "\n",
    "total.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
